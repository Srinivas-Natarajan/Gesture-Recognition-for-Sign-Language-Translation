<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="./css/aboutus-style.css">
</head>
<body>
    
    <div id="nav-bar">
        <nav class="navbar navbar-expand-lg navbar-light bg-dark ">
            <a class="navbar-brand" href="#"><img src="./assets/logo_cropped.png"></a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-expanded="true" aria-label="Toggle navigation" aria-controls="navbarNav">
              <span class="navbar-toggler-icon"></span>
            </button>
            <div class="navbar-collapse collapse show" id="navbarNav" style="">
              <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                  <a class="nav-link" href="./sample.html">TRANSLATE</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="./info.html">INFO</a>
                </li>            
                <li class="nav-item">
                    <a class="nav-link" href="./aboutus.html">ABOUT US</a>
                </li>
              </ul>
            </div>
          </nav>
    <div>
    <div class="about-section">
        <div class="inner-container">
            <h1>About Us</h1>
            <p class="text">
                
                We are three friends Rahul, Srinivas and Rachit from Vellore Institute of Technology, who teamed up for their Final Year Project i.e Capstone to create and application that can tuly help the people in need. 
                We set out to find new developments in the feild of Live gesture capture and see how it could help us in creating an interface that lets you live translate ASL gestures in real time.
                We realised that the models being used in the existing work worked only on high processing power platforms, untill we came across mediapipe from google.
                We harnessed medipipes capabilities to create a live gesture capturing for ASL characters and phrases to work with low processing power plaftorms like mobile phones.
                We created out own datasets for this approach and then finally created an android app to help people even learn ASL along with out new Live Gesture translations to practice ASL.
                We hope this helps hearing impared people in their lives.
            </p>
            <div class="skills">
                <span>SRINIVAS 18BCE0048</span>
                <span>RAHUL 18BCE0018</span>
                <span>RACHIT 18BCE0873</span>
            </div>
        </div>
    </div>
    </div>
</body>
</html>